from __future__ import annotations

import asyncio
import os
import time
from dataclasses import dataclass

try:
    from browser_use import Agent, Browser
    from browser_use.llm import ChatOpenAI
except ImportError:
    # Allow running without browser_use installed (e.g. for context verification)
    Agent = None
    Browser = None
    ChatOpenAI = None

from exogram.execution.auth import get_cdp_compatible_auth_file
from exogram.utils import get_logger

logger = get_logger("Executor")

# è°ƒè¯•ï¼šå¯ç”¨è¯¦ç»†è®¡æ—¶æ—¥å¿—
DEBUG_TIMING = os.getenv("EXOGRAM_DEBUG_TIMING", "0") == "1"

# æ€§èƒ½ä¼˜åŒ–ï¼šå¯ç”¨ flash_modeï¼ˆè·³è¿‡è¯„ä¼°ã€ç›®æ ‡ã€æ€è€ƒï¼Œåªç”¨ memoryï¼‰
FLASH_MODE = os.getenv("EXOGRAM_FLASH_MODE", "0") == "1"


def _log_timing(label: str, start: float) -> None:
    """è¾“å‡ºè®¡æ—¶æ—¥å¿—"""
    elapsed = time.time() - start
    logger.info(f"â±ï¸ {label}: {elapsed:.2f}s")


@dataclass(frozen=True)
class RunResult:
    injected_wisdom: str
    history: object


class Executor:
    """åŸºäºè®¤çŸ¥æ‰§è¡Œä»»åŠ¡çš„æ‰§è¡Œå™¨"""
    
    def __init__(
        self,
        *,
        model: str,
        openai_api_key: str | None,
        openai_base_url: str | None,
        openai_timeout: float,
        openai_max_retries: int,
        temperature: float,
        max_completion_tokens: int,
        start_url: str | None = None,
    ) -> None:
        self.model = model
        self.openai_api_key = openai_api_key
        self.openai_base_url = openai_base_url
        self.openai_timeout = openai_timeout
        self.openai_max_retries = openai_max_retries
        self.temperature = temperature
        self.max_completion_tokens = max_completion_tokens
        self.start_url = start_url

    async def run(self, *, task: str, wisdom: str | None = None) -> RunResult:
        total_start = time.time()
        wisdom = (wisdom or "").strip()
        
        # æ„å»ºå¸¦è®¤çŸ¥çš„ä»»åŠ¡
        full_task = task.strip()
        if wisdom:
            full_task = f"{task.strip()}\n\nã€è®¤çŸ¥æŒ‡å¯¼ã€‘\n{wisdom}\n"

        # é…ç½®æµè§ˆå™¨
        browser_kwargs = {
            "headless": False,
            "disable_security": True,
            "enable_default_extensions": False,
        }
        

        # è°ƒè¯•ï¼šå‡å°‘ç­‰å¾…æ—¶é—´
        if DEBUG_TIMING:
            browser_kwargs["minimum_wait_page_load_time"] = 0.1
            browser_kwargs["wait_for_network_idle_page_load_time"] = 0.3
            browser_kwargs["wait_between_actions"] = 0.3
            logger.info("ğŸ”§ è°ƒè¯•æ¨¡å¼ï¼šå·²å‡å°‘ç­‰å¾…æ—¶é—´")
        
        # è‡ªåŠ¨åŠ è½½è®¤è¯çŠ¶æ€
        t0 = time.time()
        if self.start_url:
            auth_file = get_cdp_compatible_auth_file(self.start_url)
            if auth_file:
                browser_kwargs["storage_state"] = auth_file
                logger.info("å·²åŠ è½½è®¤è¯çŠ¶æ€")
            full_task = f"é¦–å…ˆæ‰“å¼€ç½‘å€: {self.start_url}\n\n{full_task}"
        if DEBUG_TIMING:
            _log_timing("è®¤è¯æ–‡ä»¶åŠ è½½", t0)
        
        # å¯åŠ¨æµè§ˆå™¨
        t0 = time.time()
        browser = Browser(**browser_kwargs)
        if DEBUG_TIMING:
            _log_timing("Browserå¯¹è±¡åˆ›å»º", t0)
        
        # DeepSeek å®˜æ–¹ API ä¸æ”¯æŒ structured outputï¼Œéœ€è¦ç¦ç”¨
        # åŒæ—¶å°† schema åŠ å…¥ system prompt ä»¥æé«˜æ ¼å¼æ­£ç¡®ç‡
        is_deepseek = self.openai_base_url and "deepseek.com" in self.openai_base_url
        llm = ChatOpenAI(
            model=self.model,
            api_key=self.openai_api_key or os.getenv("OPENAI_API_KEY"),
            base_url=self.openai_base_url,
            timeout=self.openai_timeout,
            max_retries=self.openai_max_retries,
            temperature=self.temperature,
            max_completion_tokens=self.max_completion_tokens,
            dont_force_structured_output=is_deepseek,
            add_schema_to_system_prompt=is_deepseek,
        )
        
        # åˆ›å»º Agentï¼ˆæ€§èƒ½ä¼˜åŒ–å‚æ•°ï¼‰
        agent_kwargs = {
            "task": full_task,
            "llm": llm,
            "browser": browser,
        }
        
        if FLASH_MODE:
            agent_kwargs["flash_mode"] = True           # è·³è¿‡è¯„ä¼°ã€ç›®æ ‡ã€æ€è€ƒï¼Œåªç”¨ memory
            agent_kwargs["max_history_items"] = 10      # åªä¿ç•™æœ€è¿‘ 10 æ­¥å†å²ï¼ˆæœ€å°å€¼è¦æ±‚ > 5ï¼‰
            agent_kwargs["max_actions_per_step"] = 4    # æ¯æ­¥æœ€å¤š 4 ä¸ªåŠ¨ä½œ
            logger.info("âš¡ Flash æ¨¡å¼å·²å¯ç”¨ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
        
        agent = Agent(**agent_kwargs)
        
        # åˆ›å»ºæ­¥éª¤è®¡æ—¶å›è°ƒ
        step_count = 0
        step_start_time = time.time()
        
        async def on_step_start(agent_instance):
            nonlocal step_start_time
            step_start_time = time.time()
        
        async def on_step_end(agent_instance):
            nonlocal step_count, step_start_time
            step_count += 1
            elapsed = time.time() - step_start_time
            if DEBUG_TIMING:
                logger.info(f"â±ï¸ Step {step_count} è€—æ—¶: {elapsed:.2f}s")
        
        # è¿è¡Œ Agent
        t0 = time.time()
        logger.info("ğŸš€ Agent å¼€å§‹æ‰§è¡Œ...")
        history = await agent.run(on_step_start=on_step_start, on_step_end=on_step_end)
        if DEBUG_TIMING:
            _log_timing("Agent.run() æ€»è€—æ—¶", t0)
            _log_timing("æ•´ä½“æ‰§è¡Œæ€»è€—æ—¶", total_start)
            logger.info(f"ğŸ“Š æ€»æ­¥æ•°: {step_count}")
        
        return RunResult(injected_wisdom=wisdom, history=history)

    def run_sync(self, *, task: str, wisdom: str | None = None) -> RunResult:
        return asyncio.run(self.run(task=task, wisdom=wisdom))
